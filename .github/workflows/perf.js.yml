name: Perf Test

on:
  push:
    branches: [main]

jobs:
  benchmark:
    name: Performance regression check
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v1
        with:
          node-version: 16.x

      # Clear out potential user data dirs left over from previous failures.
      - run: rm -rf /tmp/replicache-playwright-*
      - name: configure npm auth token
        run: npm config set '//registry.npmjs.org/:_authToken' "${NPM_TOKEN}"
        env:
          NPM_TOKEN: ${{secrets.NPM_TOKEN}}
      - run: npm ci
      - run: npx playwright install-deps
      - run: npm run build --if-present

      # Run benchmark and stores the output to a file
      - name: Run benchmark
        run: node perf/runner.js | tee output.txt

      # Run `github-action-benchmark` action
      - name: Store benchmark result
        uses: rhysd/github-action-benchmark@v1
        with:
          # What benchmark tool the output.txt came from
          tool: 'benchmarkjs'
          # Where the output from the benchmark tool is stored
          output-file-path: output.txt
          # This version of the dashboard is flakier, we don't need to alert when it fails
          # Just maintaining it for a bit longer "in case"?
          fail-on-alert: false
          github-token: ${{ secrets.PERSONAL_GITHUB_TOKEN }}
          benchmark-data-dir-path: perf
          auto-push: true
          alert-threshold: '130%'
          comment-on-alert: false
#       - name: Deploy perf data
#         run: curl -X POST ${{ secrets.VERCEL_DEPLOY_PERF_DATA_URL }}
